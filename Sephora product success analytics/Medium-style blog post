**What Drives High-Performing Products at Sephora? A Product + Consumer Analytics Case Study**

```markdown
# What Drives High-Performing Products at Sephora?  
## A Product + Consumer Analytics Case Study Using 1M+ Reviews

Sephora sells thousands of products across skincare, makeup, and fragrance. For customers, that variety is exciting. For retailers, it creates a harder problem: **which products become “winners,” and why?**

This case study combines product metadata with over **1 million customer reviews** to answer two executive-level questions:

1) *What distinguishes high-performing products from the rest of the catalog?*  
2) *What do customers consistently praise or criticize in products that succeed?*

I built this project as part of my marketing analytics portfolio to demonstrate an executive-facing workflow: define a measurable KPI, benchmark performance across segments, and translate customer voice into actionable strategy.

---

## Step 1: Starting with the Catalog — What Data Is Available?

I began by loading Sephora’s product dataset into Python and doing basic profiling—checking columns, data types, and missingness. This is usually an unglamorous step, but it determines everything that comes after.

In this dataset, certain pricing fields (like sale price) were frequently missing, while base price had strong coverage. That immediately influenced which metrics were usable for comparison later.

The big goal here wasn’t to produce charts—it was to answer:  
**What can I trust, and what should I avoid using as a key business metric?**

---

## Step 2: Defining “Success” as a Measurable Outcome

To answer “what drives high performance,” I needed an actual definition of high performance.

Because this dataset doesn’t include revenue or margin, I used customer engagement as a proxy—specifically the “loves” signal—and created a binary label:

- **High Performer:** products above a defined engagement threshold (top segment)
- **Non-High Performer:** everyone else

This step is a form of **feature engineering**, but it’s also a business decision. Once you define success, everything becomes testable: price, ratings, categories, and brands can all be compared against that benchmark.

---

## Step 3: Winner vs Non-Winner Benchmarking

With the “high performer” segment created, I ran direct comparisons between winners and non-winners.

The goal wasn’t to confirm assumptions—it was to validate them.

One of the most useful findings was that high-performing products were **not necessarily premium-priced**. In many cases, winners were lower priced on average.

That insight matters because it reframes product success as something driven by **perceived value and performance**, not luxury positioning. For Sephora, this suggests opportunity to win not just through “premium,” but through products that reliably deliver outcomes at accessible price points.

---

## Step 4: Categories — Measuring Both Volume and “Hit Rate”

The next question was where Sephora’s winners concentrate.

There are two ways to approach this:

- **Winner volume:** which categories contain the most high performers  
- **Success rate (“hit rate”):** within a category, what percentage of products are winners?

This distinction is important. A huge category will naturally contain more winners simply because it has more products. Success rate reveals something different: where Sephora has the best odds of a product becoming a winner.

This approach produces a much more strategy-friendly view because it helps prioritize category focus based on probability, not just size.

---

## Step 5: Brand Performance Isn’t Fair Without Controlling for Scale

At first, ranking brands by winner rate seems straightforward. But it immediately creates a problem: **brand catalogs are not the same size**.

A brand with 10 products can look amazing with a few winners. A brand with 200 products will almost always show a lower concentration of winners.

To correct for that bias, I segmented brands into tiers by catalog size:

- **Emerging brands:** 10–19 products  
- **Established brands:** 20–49 products  
- **Powerhouse brands:** 50+ products  

This tiering approach is common in real retail analytics because it supports fair benchmarking and clearer decision-making.

The executive interpretation is simple:  
**Emerging brands represent high-upside breakout opportunities, while established brands deliver the most reliable and scalable performance.**  
Powerhouse brands remain critical anchor partners, but their “winner concentration” naturally dilutes at scale.

---

## Step 6: Moving from Product Metadata to Customer Voice

Product-level metrics tell part of the story. Reviews explain the “why.”

To mine review content at scale, I consolidated review files into a single dataset (over 1 million rows) and created a sentiment proxy using star ratings:

- **Positive:** 4–5 stars  
- **Negative:** 1–2 stars  
- **Neutral:** 3 stars

This isn’t a machine learning sentiment model. It’s a simple, explainable baseline that’s easy to communicate to stakeholders.

---

## Step 7: Course Correction — Why Single Words Didn’t Work

My first instinct was to look at common words in positive vs negative reviews.

That technically worked, but the results were not stakeholder-friendly. A lot of high-frequency words were generic (“this,” “really,” “product”) or contextless (“feel,” “work”).

So I course-corrected in two ways:

1) I expanded stopword filtering (standard English stopwords + beauty-domain filler words)  
2) I shifted from single words to **phrases (n-grams)**

This change was a turning point. Phrases capture intent and context. Instead of “smell,” you get “get past smell.” Instead of “acne,” you get “sensitive acne prone.”

That makes the output dramatically more actionable.

---

## Step 8: Phrase Mining (N-grams) for Business-Ready Themes

Using 2–3 word phrases allowed me to surface repeatable drivers of satisfaction:

- hydration and softness outcomes  
- visible improvement (fine lines, brightening)  
- sensitive/acne-prone compatibility  

It also surfaced repeatable pain points:

- fragrance/smell as a deal-breaker  
- SPF finish issues (white cast)  
- value dissatisfaction (“worth price tag”)

At this point, the analysis moved from “text processing” to “consumer insight.”

---

## Step 9: The Most Important Insight — High-Stakes Attributes

One pattern stood out: the same themes appeared in both positive and negative reviews.

That isn’t a weakness. It’s a signal.

It suggests customers are consistently outcome-driven. The attributes they praise most are also the ones that cause disappointment when expectations aren’t met. These become what I call **high-stakes attributes**—areas where performance consistency matters most for satisfaction and retention.

From a product strategy lens, this is exactly what leadership needs to know:  
**what customers care about enough to create loyalty—or churn.**

---

## Recommendations: How Sephora Could Use These Insights

Based on the benchmarking + customer voice themes, the strategic actions are clear:

1) **Prioritize sensitive-skin-safe innovation**  
   Sensitive/acne-prone compatibility appears as a recurring consumer priority.

2) **Reduce sensory friction**  
   Smell/fragrance and white cast repeatedly appear as deal-breakers.

3) **Adopt tier-based brand investment**  
   Use emerging vs established vs powerhouse segmentation to guide partnership decisions and growth investments.

4) **Operationalize review-theme monitoring**  
   Treat recurring complaint phrases as early-warning signals that can inform merchandising, marketing clarity, and product development.

---

## Why This Matters (and Why I Built It)

This project demonstrates how marketing analytics can combine structured product signals with unstructured customer voice to produce strategy-ready insights.

It’s not just about which products win—it’s about why they win, where Sephora should focus, and what customer expectations matter most.

---

### Deliverables  
- Full Python notebook (data cleaning, benchmarking, visualizations, NLP phrase mining)  
- Executive-style deck summarizing insights  
- Visual assets used in reporting  

If you’d like to discuss this project or similar marketing analytics work, feel free to connect.
